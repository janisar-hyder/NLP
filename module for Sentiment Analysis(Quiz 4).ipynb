{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=red>`Quiz # 4`</font>\n",
    "##    <font color=red>Submitted By:</font> M.Janisar\n",
    "##    <font color=red>Registration No:</font> SP22-BCS-047\n",
    "##    <font color=white>______________________________________</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `File 1`     <font color=red>Classifying</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10662\n",
      "Original Naive Bayes Algo accuracy percent: 67.82477341389728\n",
      "MNB_classifier accuracy percent: 66.46525679758308\n",
      "BernoulliNB_classifier accuracy percent: 67.97583081570997\n",
      "LogisticRegression_classifier accuracy percent: 69.63746223564955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ibrahim Qureshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC_classifier accuracy percent: 66.01208459214502\n",
      "SGDClassifier accuracy percent: 67.97583081570997\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "import random\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "import pickle\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode\n",
    "from nltk.tokenize import word_tokenize\n",
    "from autocorrect import Speller\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "    \n",
    "\n",
    "\n",
    "class VoteClassifier(ClassifierI):\n",
    "    def __init__(self, *classifiers):\n",
    "        self._classifiers = classifiers\n",
    "\n",
    "    def classify(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "        return mode(votes)\n",
    "\n",
    "    def confidence(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "\n",
    "        choice_votes = votes.count(mode(votes))\n",
    "        conf = choice_votes / len(votes)\n",
    "        return conf\n",
    "    \n",
    "        \n",
    "short_pos = open(\"D:\\\\NLP\\\\pos.txt\",\"r\").read()\n",
    "short_neg = open(\"D:\\\\NLP\\\\neg.txt\",\"r\").read()\n",
    "\n",
    "\n",
    "all_words = []\n",
    "documents = []\n",
    "\n",
    "def preprocessing(text):\n",
    "    tokens = [token.text.lower() for token in nlp(text) if not token.is_stop and token.is_alpha]\n",
    "    lemmas = [token.lemma_ for token in nlp(' '.join(tokens))]\n",
    "    return lemmas\n",
    "\n",
    "\n",
    "for p in short_pos.split('\\n'):\n",
    "    documents.append((p, \"pos\"))\n",
    "    lemmas = preprocessing(p)\n",
    "    for w in lemmas:\n",
    "        all_words.append(w)\n",
    "\n",
    "for p in short_neg.split('\\n'):\n",
    "    documents.append((p, \"neg\"))\n",
    "    lemmas = preprocessing(p)\n",
    "    for w in lemmas:\n",
    "         all_words.append(w)\n",
    "\n",
    "\n",
    "#  j is adject, r is adverb, and v is verb\n",
    "# allowed_word_types = [\"J\",\"R\",\"V\"]\n",
    "# allowed_word_types = [\"J\"]\n",
    "# Processing each line in the positive and negative files\n",
    "# for p in short_pos.split('\\n'):\n",
    "#     documents.append((p, \"pos\"))\n",
    "#     lemmas = preprocessing(p)\n",
    "#     pos = nltk.pos_tag(lemmas)\n",
    "#     for w, tag in pos:\n",
    "#         if tag[0] in allowed_word_types:\n",
    "#             all_words.append(w)\n",
    "\n",
    "# for p in short_neg.split('\\n'):\n",
    "#     documents.append((p, \"neg\"))\n",
    "#     lemmas = preprocessing(p)\n",
    "#     pos = nltk.pos_tag(lemmas)\n",
    "#     for w, tag in pos:\n",
    "#         if tag[0] in allowed_word_types:\n",
    "#             all_words.append(w)\n",
    "\n",
    "\n",
    "\n",
    "save_documents = open(\"documents.pickle\",\"wb\")\n",
    "pickle.dump(documents, save_documents)\n",
    "save_documents.close()\n",
    "\n",
    "\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "\n",
    "word_features = list(all_words.keys())[:5000]\n",
    "\n",
    "\n",
    "save_word_features = open(\"word_features5k.pickle\",\"wb\")\n",
    "pickle.dump(word_features, save_word_features)\n",
    "save_word_features.close()\n",
    "\n",
    "\n",
    "def find_features(document):\n",
    "    words = word_tokenize(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features\n",
    "\n",
    "featuresets = [(find_features(rev), category) for (rev, category) in documents]\n",
    "\n",
    "featuresets_save = open(\"featuressss.pickle\",\"wb\")\n",
    "pickle.dump(featuresets, featuresets_save)\n",
    "featuresets_save.close()\n",
    "\n",
    "random.shuffle(featuresets)\n",
    "print(len(featuresets))\n",
    "\n",
    "testing_set = featuresets[10000:]\n",
    "training_set = featuresets[:10000]\n",
    "\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "print(\"Original Naive Bayes Algo accuracy percent:\", (nltk.classify.accuracy(classifier, testing_set))*100)\n",
    "\n",
    "###############\n",
    "save_classifier = open(\"originalnaivebayes5k.pickle\",\"wb\")\n",
    "pickle.dump(classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(training_set)\n",
    "print(\"MNB_classifier accuracy percent:\", (nltk.classify.accuracy(MNB_classifier, testing_set))*100)\n",
    "\n",
    "save_classifier = open(\"MNB_classifier5k.pickle\",\"wb\")\n",
    "pickle.dump(MNB_classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BernoulliNB_classifier.train(training_set)\n",
    "print(\"BernoulliNB_classifier accuracy percent:\", (nltk.classify.accuracy(BernoulliNB_classifier, testing_set))*100)\n",
    "\n",
    "save_classifier = open(\"BernoulliNB_classifier5k.pickle\",\"wb\")\n",
    "pickle.dump(BernoulliNB_classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "LogisticRegression_classifier.train(training_set)\n",
    "print(\"LogisticRegression_classifier accuracy percent:\", (nltk.classify.accuracy(LogisticRegression_classifier, testing_set))*100)\n",
    "\n",
    "save_classifier = open(\"LogisticRegression_classifier5k.pickle\",\"wb\")\n",
    "pickle.dump(LogisticRegression_classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "\n",
    "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LinearSVC_classifier.train(training_set)\n",
    "print(\"LinearSVC_classifier accuracy percent:\", (nltk.classify.accuracy(LinearSVC_classifier, testing_set))*100)\n",
    "\n",
    "save_classifier = open(\"LinearSVC_classifier5k.pickle\",\"wb\")\n",
    "pickle.dump(LinearSVC_classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "\n",
    "##NuSVC_classifier = SklearnClassifier(NuSVC())\n",
    "##NuSVC_classifier.train(training_set)\n",
    "##print(\"NuSVC_classifier accuracy percent:\", (nltk.classify.accuracy(NuSVC_classifier, testing_set))*100)\n",
    "\n",
    "\n",
    "SGDC_classifier = SklearnClassifier(SGDClassifier())\n",
    "SGDC_classifier.train(training_set)\n",
    "print(\"SGDClassifier accuracy percent:\",nltk.classify.accuracy(SGDC_classifier, testing_set)*100)\n",
    "\n",
    "save_classifier = open(\"SGDC_classifier5k.pickle\",\"wb\")\n",
    "pickle.dump(SGDC_classifier, save_classifier)\n",
    "save_classifier.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `File 2`     <font color=red>sentiment mod</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10662\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "import random\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "import pickle\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "\n",
    "class VoteClassifier(ClassifierI):\n",
    "    def __init__(self, *classifiers):\n",
    "        self._classifiers = classifiers\n",
    "\n",
    "    def classify(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "        return mode(votes)\n",
    "\n",
    "    def confidence(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "\n",
    "        choice_votes = votes.count(mode(votes))\n",
    "        conf = choice_votes / len(votes)\n",
    "        return conf\n",
    "\n",
    "\n",
    "documents_f = open(\"documents.pickle\", \"rb\")\n",
    "documents = pickle.load(documents_f)\n",
    "documents_f.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "word_features5k_f = open(\"word_features5k.pickle\", \"rb\")\n",
    "word_features = pickle.load(word_features5k_f)\n",
    "word_features5k_f.close()\n",
    "\n",
    "\n",
    "def find_features(document):\n",
    "    words = word_tokenize(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "\n",
    "featuresets_f = open(\"featuressss.pickle\", \"rb\")\n",
    "featuressss = pickle.load(featuresets_f)\n",
    "featuresets_f.close()\n",
    "\n",
    "random.shuffle(featuressss)\n",
    "print(len(featuressss))\n",
    "\n",
    "testing_set = featuressss[10000:]\n",
    "training_set = featuressss[:10000]\n",
    "\n",
    "\n",
    "\n",
    "open_file = open(\"originalnaivebayes5k.pickle\", \"rb\")\n",
    "classifier = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "\n",
    "open_file = open(\"MNB_classifier5k.pickle\", \"rb\")\n",
    "MNB_classifier = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "\n",
    "\n",
    "open_file = open(\"BernoulliNB_classifier5k.pickle\", \"rb\")\n",
    "BernoulliNB_classifier = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "\n",
    "open_file = open(\"LogisticRegression_classifier5k.pickle\", \"rb\")\n",
    "LogisticRegression_classifier = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "\n",
    "open_file = open(\"LinearSVC_classifier5k.pickle\", \"rb\")\n",
    "LinearSVC_classifier = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "\n",
    "open_file = open(\"SGDC_classifier5k.pickle\", \"rb\")\n",
    "SGDC_classifier = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "voted_classifier = VoteClassifier(\n",
    "                                  classifier,\n",
    "                                  LinearSVC_classifier,\n",
    "                                  MNB_classifier,\n",
    "                                  BernoulliNB_classifier,\n",
    "                                  LogisticRegression_classifier)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sentiment(text):\n",
    "    feats = find_features(text)\n",
    "    return voted_classifier.classify(feats),voted_classifier.confidence(feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `File 3`     <font color=red>Visualizing</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('neg', 0.8)\n",
      "('neg', 0.8)\n",
      "('neg', 0.8)\n",
      "('neg', 1.0)\n",
      "('pos', 1.0)\n",
      "('pos', 0.6)\n",
      "('pos', 0.6)\n",
      "('pos', 1.0)\n",
      "('pos', 1.0)\n",
      "('pos', 1.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(sentiment(\"REal eyes realise lies\"))\n",
    "print(sentiment(\"The art of knowing is knowing what to ignore\"))\n",
    "print(sentiment(\"Life is fragile and temporary. The faces of today quickly become the faces of the past. Sorrow, pain, and anger..it all fades\"))\n",
    "print(sentiment(\"Learn from the mistakes of others. You can't live long enough to make them all yourself.\"))\n",
    "print(sentiment(\"Her beauty is laced in her strength and interwoven through her flaws. She embodies perfection.\"))\n",
    "print(sentiment(\"Every battle is lost or won in the arena of the mind.\"))\n",
    "print(sentiment(\"Can you stay Until the last stretched moments that will be taken away soon In your presence love felt like moonlight But In your absence It's burning my chest as If my heart has been set on fire.\"))\n",
    "print(sentiment(\"I hope that you never cower from your dark chapters, but highlight them as proof of perseverance, endurance, and strength.\"))\n",
    "print(sentiment(\"If you world feels dark, shine your light a little brighter! the world needs a little more of your smile, your heart and your soul\"))\n",
    "print(sentiment(\"You maintain the integrity of things your honor no matter how old or new, expensive or inexpensive....simply stated, you dignify it for it's being... that's love.\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "530\n",
      "['title', 'navigate', 'complexity', 'artificial', 'intelligence', 'comprehensive', 'analysis', 'introduction', 'artificial', 'intelligence', 'emerge', 'transformative', 'force', 'escape', 'modern', 'world', 'industry', 'economy', 'society', 'streamline', 'process', 'healthcare', 'finance', 'revolutionize', 'communication', 'transportation', 'influence', 'pervasive', 'profound', 'essay', 'offer', 'depth', 'exploration', 'multifacete', 'impact', 'leave', 'evolution', 'current', 'application', 'future', 'implication', 'evolution', 'artificial', 'intelligence', 'root', 'trace', 'century', 'seminal', 'work', 'pioneer', 'alan', 'john', 'mccarthy', 'lay', 'groundwork', 'development', 'decade', 'advancement', 'compute', 'power', 'algorithm', 'datum', 'availability', 'propel', 'theoretical', 'concept', 'practical', 'application', 'expert', 'system', 'rule', 'base', 'approach', 'machine', 'learn', 'deep', 'learning', 'evolve', 'rapidly', 'drive', 'innovation', 'domain', 'practice', 'application', 'industry', 'adoption', 'span', 'diverse', 'sector', 'harvesting', 'capability', 'address', 'unique', 'challenge', 'opportunity', 'healthcare', 'power', 'diagnostic', 'tool', 'assist', 'clinician', 'interpret', 'medical', 'image', 'identify', 'pattern', 'patient', 'datum', 'lead', 'accurate', 'diagnosis', 'personalize', 'treatment', 'financial', 'institution', 'leverage', 'algorithm', 'risk', 'assessment', 'fraud', 'detection', 'algorithmic', 'trading', 'enhance', 'decision', 'make', 'optimize', 'operation', 'furthermore', 'drive', 'innovation', 'entertainment', 'recommendation', 'system', 'content', 'generation', 'algorithm', 'cater', 'individual', 'preference', 'drive', 'user', 'engagement', 'transportation', 'autonomous', 'vehicle', 'powered', 'promise', 'revolutionize', 'mobility', 'reduce', 'accident', 'congestion', 'transform', 'urban', 'landscape', 'additionally', 'power', 'virtual', 'assistant', 'chariot', 'ubiquitous', 'provide', 'personalized', 'assistance', 'enhance', 'user', 'experience', 'digital', 'platform', 'economic', 'implication', 'opportunity', 'challenge', 'economic', 'impact', 'profound', 'escape', 'labor', 'market', 'business', 'model', 'global', 'competitiveness', 'drive', 'automation', 'increase', 'productivity', 'efficiency', 'raise', 'concern', 'job', 'displacement', 'income', 'inequality', 'proponent', 'argue', 'create', 'new', 'opportunity', 'employment', 'emerge', 'field', 'data', 'science', 'ethic', 'human', 'machine', 'interaction', 'integration', 'industry', 'foster', 'innovation', 'entrepreneurship', 'drive', 'economic', 'growth', 'competitiveness', 'government', 'policymaker', 'face', 'challenge', 'balance', 'benefit', 'drive', 'innovation', 'need', 'ensure', 'social', 'exclusivity', 'economic', 'stability', 'investment', 'education', 'reskille', 'workforce', 'development', 'essential', 'equip', 'individual', 'skill', 'need', 'thrive', 'drive', 'economy', 'ethical', 'societal', 'implication', 'ethical', 'implication', 'wide', 'range', 'encompass', 'issue', 'privacy', 'bias', 'transparency', 'accountability', 'collection', 'analysis', 'vast', 'amount', 'personal', 'datum', 'raise', 'concern', 'surveillance', 'privacy', 'infringement', 'necessitating', 'robust', 'data', 'protection', 'regulation', 'ethical', 'guideline', 'algorithm', 'perpetuate', 'bias', 'present', 'training', 'datum', 'lead', 'discriminatory', 'outcome', 'area', 'hire', 'lend', 'criminal', 'justice', 'ensure', 'transparency', 'fairness', 'decision', 'making', 'process', 'crucial', 'building', 'trust', 'mitigate', 'risk', 'additionally', 'drive', 'technology', 'raise', 'complex', 'ethical', 'dilemmas', 'development', 'autonomous', 'weapon', 'system', 'implication', 'shape', 'human', 'behavior', 'cognition', 'ethical', 'framework', 'interdisciplinary', 'collaboration', 'essential', 'navigate', 'challenge', 'promote', 'responsible', 'development', 'deployment', 'challenge', 'risk', 'address', 'unknown', 'despite', 'transformative', 'potential', 'pose', 'significant', 'challenge', 'risk', 'address', 'proactive', 'technical', 'challenge', 'ensure', 'reliability', 'safety', 'system', 'require', 'interdisciplinary', 'research', 'collaboration', 'black', 'box', 'nature', 'algorithm', 'impede', 'understand', 'oversight', 'raise', 'concern', 'unintended', 'consequence', 'unforeseen', 'risk', 'furthermore', 'proliferation', 'drive', 'disinformation', 'malicious', 'use', 'technology', 'pose', 'threat', 'societal', 'cohesion', 'democratic', 'institution', 'deepak', 'technology', 'use', 'create', 'convince', 'synthetic', 'medium', 'raise', 'concern', 'misinformation', 'digital', 'manipulation', 'address', 'challenge', 'require', 'multifaceted', 'approach', 'involve', 'collaboration', 'technology', 'developer', 'policymaker', 'researcher', 'civil', 'society', 'stakeholder', 'future', 'outlook', 'responsible', 'innovation', 'continue', 'advance', 'impact', 'society', 'intensify', 'present', 'opportunity', 'challenge', 'build', 'future', 'serve', 'collective', 'good', 'require', 'proactive', 'effort', 'address', 'ethical', 'social', 'economic', 'consideration', 'invest', 'education', 'literacy', 'essential', 'empower', 'individual', 'understand', 'engage', 'technology', 'responsibly', 'foster', 'diverse', 'inclusive', 'participation', 'research', 'development', 'crucial', 'ensuring', 'reflect', 'value', 'need', 'diverse', 'community', 'regulatory', 'framework', 'governance', 'mechanism', 'adapt', 'evolve', 'landscape', 'balance', 'innovation', 'ethical', 'consideration', 'societal', 'impact', 'foster', 'culture', 'responsible', 'innovation', 'harness', 'potential', 'address', 'press', 'global', 'challenge', 'build', 'equitable', 'sustainable', 'future', 'conclusion', 'conclusion', 'rise', 'artificial', 'intelligence', 'mark', 'pivotal', 'moment', 'human', 'history', 'profound', 'implication', 'society', 'economy', 'governance', 'revolutionize', 'industry', 'escape', 'labor', 'market', 'raise', 'ethical', 'societal', 'concern', 'influence', 'far', 'reach', 'complex', 'navigate', 'complexity', 'require', 'collaborative', 'effort', 'sector', 'discipline', 'ground', 'ethical', 'principle', 'commitment', 'promote', 'common', 'good', 'foster', 'responsible', 'innovation', 'harness', 'transformative', 'potential', 'create', 'well', 'future', 'humanity']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import spacy\n",
    "import pickle\n",
    "nlp=spacy.load(\"en_core_web_sm\")\n",
    "from autocorrect import Speller\n",
    "spell_Check = Speller()\n",
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "path = 'D:\\\\NLP\\\\'\n",
    "filepath = os.listdir(path)\n",
    "\n",
    "D_S = []\n",
    "\n",
    "def filetext(filename):\n",
    "    for file in filename:\n",
    "        text = open(\"D:\\\\NLP\\\\\" + file, \"r\", encoding=\"utf-8\").read()\n",
    "        index = [text, type(text)]\n",
    "        D_S.append(index)\n",
    "\n",
    "filetext(filepath)\n",
    "\n",
    "\n",
    "\n",
    "def spell_correction(text):\n",
    "    text=spell_Check(text)\n",
    "    return text\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = nlp(text)\n",
    "    return tokens\n",
    "\n",
    "def StopWords_Removal(tokens):\n",
    "    stopword_removal = [t.text for t in tokens if t.is_alpha and not  t.is_stop]\n",
    "    return stopword_removal\n",
    "\n",
    "def POS_Tagging(stopword_removal):\n",
    "    pos_tags = [(t.text, t.pos_, t.tag_) for t in stopword_removal]\n",
    "    return pos_tags\n",
    "\n",
    "\n",
    "def convert_to_lowercase(pos_tags):\n",
    "    tokens_in_lowercase = [w.lower() for w in pos_tags]\n",
    "    return tokens_in_lowercase\n",
    "\n",
    "def Lemmatization(tokens_in_lowercase):\n",
    "    lemmas = [token.lemma_ for token in nlp(\" \".join(tokens_in_lowercase))]\n",
    "    return lemmas\n",
    "\n",
    "DSP=[]\n",
    "for ds in D_S:\n",
    "    text = ds[0]\n",
    "    DSP_item = []\n",
    "    corrected_text = spell_correction(text)\n",
    "    DSP_item.append(corrected_text) \n",
    "    \n",
    "    tokkens = tokenize(corrected_text)\n",
    "    DSP_item.append(tokkens)\n",
    "\n",
    "    DSP_item.append(POS_Tagging(tokkens))\n",
    "\n",
    "    T_WSW = StopWords_Removal(tokkens)\n",
    "    DSP_item.append(T_WSW)                                                                                                                                 \n",
    "\n",
    "    T_LLC = convert_to_lowercase(T_WSW)\n",
    "    DSP_item.append(T_LLC) \n",
    "    lemmas = Lemmatization(T_LLC)\n",
    "    DSP_item.append(lemmas) \n",
    "    DSP.append(DSP_item)\n",
    "\n",
    "\n",
    "newfile=open(\"Pickledfilebyjanisar.pickle\",\"wb\")\n",
    "pickle.dump(DSP,newfile)\n",
    "newfile.close()\n",
    "\n",
    "myfile=open(\"Pickledfilebyjanisar.pickle\",\"rb\")\n",
    "DSP=pickle.load(myfile)\n",
    "\n",
    "\n",
    "\n",
    "BOW=[]\n",
    "for ds in DSP:\n",
    "    lemmas = ds[-1]\n",
    "    for l in lemmas:\n",
    "        BOW.append(l)\n",
    "print(len(BOW))\n",
    "\n",
    "print(BOW)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
